<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>James Heald</title>
  
  <meta name="author" content="James Heald">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>James Heald</name>
              </p>
              <p>I am a Research Fellow working with <a href="https://profiles.ucl.ac.uk/9384-maneesh-sahani">Maneesh Sahani</a> at the <a href="https://www.ucl.ac.uk/gatsby">Gatsby Unit, UCL</a>. Previously, I worked as a postdoctoral researcher at the <a href="https://zuckermaninstitute.columbia.edu/">Zuckerman Mind Brain Behavior Institute, Columbia University</a> with <a href="https://wolpertlab.neuroscience.columbia.edu/people/daniel-wolpert">Daniel Wolpert</a>.
              </p>
              <p>
                I received a PhD in Engineering from the University of Cambridge, where I trained in the <a href="http://learning.eng.cam.ac.uk/Public/">Computational and Biological Learning Lab</a> under the supervision of Daniel Wolpert (primary supervisor) and <a href="https://www.cbl-cambridge.org/lengyel">M&aacute;t&eacute; Lengyel</a> (secondary advisor). Prior to my PhD, I worked as a medical doctor in the NHS, and before that, I received an MSc in Cognitive and Computational Neuroscience from The University of Sheffield and an MBChB in Medicine from The University of Manchester.

              </p>
              <p style="text-align:center">
                <a href="mailto:jheald@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=NvVK7oIAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/jamesheald">GitHub</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/james-heald-519b2916a/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://twitter.com/HealdJbh40">Twitter</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:40%">
              <a href="images/james_heald_gatsby_circled.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/james_heald_gatsby_circled.png"" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in replicating human dexterity using methods from probabilistic machine learning and reinforcement learning, with an emphasis on unsupervised reinforcement learning. <!-- My research interests span model-based RL, representation learning, transfer learning and imitation learning.-->
              </p>
			  <p>
				I am an <a href="https://github.com/MyoHub/myosuite/graphs/contributors">active contributor</a> to the open-source platform <a href="https://github.com/MyoHub/myosuite">MyoSuite</a>, participating in biweekly development meetings. Working collaboratively and independently, I have:
				<ul>
					<li><a href="https://github.com/MyoHub/myosuite/tree/mjx/myosuite/envs/myo/mjx">Ported environments from MuJoCo to MuJoCo XLA</a>, enabling massively parallel, GPU-accelerated simulations.</li>
					<li>Desiged <a href="https://myosuite.readthedocs.io/en/latest/suite.html#arm-reach">new musculoskeletal models and tasks</a> for the wider research community.</li>
					<li>Built an <a href="https://github.com/MyoHub/myosuite/tree/main/myosuite/envs/myo/myoedits">API</a> to allow users to modify MuJoCo models for their own research needs.</li>
				</ul>
				I have also made contributions to <a href="https://github.com/araffin/sbx">SBX</a>, <a href="https://github.com/google/brax">BRAX</a> and <a href="https://github.com/google-deepmind/mujoco">MuJoCo XLA</a>.
              </p>
			  <p>
              Outstanding research achievements are <span class="highlight">highlighted</span> below.
		      </p>
            </td>
          </tr>
        </tbody></table>

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
		  <td style="padding:20px;width:100%;vertical-align:middle">
		    <heading>Competitions</heading>
		  </td>
		</tr>
		<tr style="background-color:#ffffd0;">
		  <td style="padding:20px;width:100%;vertical-align:middle">
	    <p>
	    <a href="https://sites.google.com/view/myosuite/myochallenge/myochallenge-2024">
      	      <papertitle>MyoChallenge 24: Physiological Dexterity and Agility in Bionic Humans</papertitle>
            </a>
	    <br>
	    Team Muscle Heads: <strong>James Heald</strong>, Kai Biegun, Samo Hromadka, Maneesh Sahani
	    <br>
	    <a href="https://neurips.cc/Conferences/2024/CompetitionTrack">
      	      <papertitle>NeurIPS 2024 Competition Track Program</papertitle>
            </a>
            </p>
            <p></p>
            <p>Our team came &#x1F947; <font color="red"><strong>first place</strong></font> &#x1F947; in the NeurIPS 2024 MyoChallenge Manipulation Track, winning a $2,000 prize for advancing high-dimensional control of overactuated systems. The challenge involved coordinating a biologically-realistic arm with 63 muscles and a robotic prosthetic arm with 17 DoFs to transfer objects between two pillars. Environment features (e.g. object properties, pillar locations) were randomized on each episode. To control the musculoskeletal arm, I developed a novel algorithm to learn a low-dimensional control manifold in high-dimensional action spaces. This allowed us to perform efficient policy search to acquire dexterous reaching and grasping skills. To control the robotic prosthetic arm, we combined a learned policy with inverse kinematic control, enabling smooth hand-offs and object relocation. Curriculum learning and reward shaping were used to solve the task in stages (reach, grasp, handover, move object to goal) .</p>
            </td>
          </tr>

 	  <tr>
 	    <td style="display: flex; padding: 20px;"> 
   	    <div style="flex: 50%; text-align: center;"> 
 	        <img src="images/myochallenge24.gif" alt="Descriptive Text for GIF" style="max-width: 100%;"> 
    	     <p>Our winning solution, showcasing robustness to random pillar locations and object properties (weight, size and friction).</p>
    	   </div>
    	   <div style="margin-left: 10px; flex: 50%; text-align: center;"> 
    	     <img src="images/myochallenge_24_leaderboard.png" alt="Descriptive Text for PNG" style="max-width: 100%;">
    	     <p>Our solution ranked first on all metrics: score, time, effort and peak contact force.</p>
    	   </div>
   	  </td>
 	  </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Select publications</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr style="padding:0px">
            <td style="padding:20px;width:25%;max-width:25%">
              <img style="width:100%;max-width:100%" alt="arn image" src="images/ARN.png">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-neuro-092322-100402?journalCode=neuro">
                <papertitle>The computational and neural bases of context-dependent learning</papertitle>
              </a>
              <br>
              <strong>James Heald</strong>, Daniel Wolpert&#42;, M&aacute;t&eacute; Lengyel&#42;
              <br>
              <em>Annual Review of Neuroscience</em>, 2023
              <br>
              <p></p>
              <p>We review a theoretical approach to formalizing context-dependent learning in the face of contextual uncertainty and the core computations it requires. We show how this approach organizes a large body of disparate experimental observations, from multiple levels of brain organization (including cells, circuits, systems and behavior) and multiple brain regions (most prominently the prefrontal cortex, the hippocampus and motor cortices), into a coherent framework. We argue that contextual inference may also be key to understanding continual learning in the brain.</p>
            </td>
          </tr>

          <tr style="padding:0px">
            <td style="padding:20px;width:25%;max-width:25%">
              <img style="width:100%;max-width:100%" alt="tics image" src="images/TICS_cover.jpg">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(22)00265-0">
                <papertitle>Contextual inference in learning and memory</papertitle>
              </a>
              <br>
              <strong>James Heald</strong>, M&aacute;t&eacute; Lengyel&#42;, Daniel Wolpert&#42;
              <br>
              <em>Trends in Cognitive Sciences</em>, 2023 &nbsp <font color="red"><strong>(Feature Review and Issue Cover)</strong></font>
              <br>
              <a href="https://www.cell.com/action/showPdf?pii=S1364-6613%2822%2900265-0">PDF</a> /
	      <a href="https://www.cell.com/trends/cognitive-sciences/issue?pii=S1364-6613(22)X0002-8">Issue Cover</a>
              <p></p>
              <p>In this issue of Trends in Cognitive Sciences, we review a computational framework of repertoire learning that provides a unifying account of phenomena across numerous domains, including conditioning, episodic memory, economic decision making and motor learning.</p>
            </td>
          </tr>

          <tr style="padding:0px" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;max-width:25%">
              <img style="width:100%;max-width:100%" alt="coin image" src="images/COIN_inference.png">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.nature.com/articles/s41586-021-04129-3">
                <papertitle>Contextual inference underlies the learning of sensorimotor repertoires</papertitle>
              </a>
              <br>
              <strong>James Heald</strong>, M&aacute;t&eacute; Lengyel&#42;, Daniel Wolpert&#42;
              <br>
              <em>Nature</em>, 2021 &nbsp <font color="red"><strong>(accompanied by News and Views)</strong></font>
              <br>
              <a href="https://www.nature.com/articles/s41586-021-04129-3.epdf?sharing_token=N2D8PDVPHK-5fLrjIs7dV9RgN0jAjWel9jnR3ZoTv0PddheUPhFUzUPUOK281N2TMEkyP39U19_7kcc0STGSqiUa355VvD-Cv0k-Xe-g1Lj1Kpc8R3H-e-sUsBZ_IlxJiqdnODc64h-MPkevlGqpr2eA1Lvs1A9rW18uDnvbnCA%3D">PDF</a> /
              <a href="https://github.com/jamesheald/COIN">Code</a> /
              <a href="https://datadryad.org/stash/dataset/doi:10.5061/dryad.m63xsj42r">Data</a> /
              <a href="https://www.nature.com/articles/d41586-021-03028-x">New and Views</a>
              <p></p>
              <p>We develop a theory of motor learning based on the principle of contextual inference. Our theory reveals that adaptation can arise by both creating and updating memories and changing how existing memories are differentially expressed.</p>
              <p></p>
            </td>
          </tr>

          <tr style="padding:0px">
            <td style="padding:20px;width:25%;max-width:25%">
              <img style="width:100%;max-width:100%" alt="control points image" src="images/control_points.png">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.nature.com/articles/s41562-018-0324-5">
                <papertitle>Multiple motor memories are learned to control different points on a tool</papertitle>
              </a>
              <br>
              <strong>James Heald</strong>, James Ingram, J. Randall Flanagan, Daniel Wolpert
              <br>
              <em>Nature Human Behaviour</em>, 2018
              <br>
              <a href="https://www.nature.com/articles/s41562-018-0324-5.epdf?sharing_token=8nSw5VDq9H6M0tpLoc0bItRgN0jAjWel9jnR3ZoTv0PlzuLK-gIlFdVZglHwfTaUjwLzSEWVHRuVLFWg5i-uYePMZN6iM8sQviCnPskEXOahiJqyQ32F-c_3j5YAi5bNPzJr5mx2VrDlf399jQVUxeUYNGMAiYbe6BUV34-Kod0%3D">PDF</a> /
              <a href="https://github.com/jamesheald/SSSM">Code</a>
              <p></p>
              <p>Different parts of tools are often handled in different ways. This study presents a computational model explaining how humans build separate motor memories for different parts of the same object.</p>
              <p></p>
            </td>
          </tr>
        </tbody></table>

<!--         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Select review articles</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr style="padding:0px">
            <td style="padding:20px;width:25%;max-width:25%">
              <img style="width:100%;max-width:100%" alt="control points image" src="images/control_points.png">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.nature.com/articles/s41562-018-0324-5">
                <papertitle>Multiple motor memories are learned to control different points on a tool</papertitle>
              </a>
              <br>
              <strong>James Heald</strong>, James Ingram, J. Randall Flanagan, Daniel Wolpert
              <br>
              <em>Nature Human Behaviour</em>, 2018
              <br>
              <a href="https://www.nature.com/articles/s41562-018-0324-5.epdf?sharing_token=8nSw5VDq9H6M0tpLoc0bItRgN0jAjWel9jnR3ZoTv0PlzuLK-gIlFdVZglHwfTaUjwLzSEWVHRuVLFWg5i-uYePMZN6iM8sQviCnPskEXOahiJqyQ32F-c_3j5YAi5bNPzJr5mx2VrDlf399jQVUxeUYNGMAiYbe6BUV34-Kod0%3D">PDF</a> /
              <a href="https://github.com/jamesheald/SSSM">Code</a>
              <p></p>
              <p>Different parts of tools are often handled in different ways. This study presents a computational model explaining how humans build separate motor memories for different parts of the same object.</p>
              <p></p>
            </td>
          </tr>

          <tr style="padding:0px">
            <td style="padding:20px;width:25%;max-width:25%">
              <img style="width:100%;max-width:100%" alt="control points image" src="images/control_points.png">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.nature.com/articles/s41562-018-0324-5">
                <papertitle>Multiple motor memories are learned to control different points on a tool</papertitle>
              </a>
              <br>
              <strong>James Heald</strong>, James Ingram, J. Randall Flanagan, Daniel Wolpert
              <br>
              <em>Nature Human Behaviour</em>, 2018
              <br>
              <a href="https://www.nature.com/articles/s41562-018-0324-5.epdf?sharing_token=8nSw5VDq9H6M0tpLoc0bItRgN0jAjWel9jnR3ZoTv0PlzuLK-gIlFdVZglHwfTaUjwLzSEWVHRuVLFWg5i-uYePMZN6iM8sQviCnPskEXOahiJqyQ32F-c_3j5YAi5bNPzJr5mx2VrDlf399jQVUxeUYNGMAiYbe6BUV34-Kod0%3D">PDF</a> /
              <a href="https://github.com/jamesheald/SSSM">Code</a>
              <p></p>
              <p>Different parts of tools are often handled in different ways. This study presents a computational model explaining how humans build separate motor memories for different parts of the same object.</p>
              <p></p>
            </td>
          </tr>
					
        </tbody></table> -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">website template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
